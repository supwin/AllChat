# app/services/chatbot_logic.py
import re
from typing import List, Dict, Any, Optional
from google.generativeai.types import content_types
import datetime
from firebase_admin import firestore # ‚ú® ‡πÄ‡∏û‡∏¥‡πà‡∏° import ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô

# ‚ú® ‡∏¢‡πâ‡∏≤‡∏¢ `db` ‡∏°‡∏≤ import ‡∏à‡∏≤‡∏Å `firebase_utils` ‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö `firestore` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô
from ..services.firebase_utils import db
from ..config.settings import get_gemini_end_user_model, get_openai_client
from ..prompts.summarization_prompt import SUMMARIZATION_PROMPT

# Constants for conversational summarization
SUMMARIZATION_THRESHOLD = 10
RECENT_MESSAGES_TO_KEEP = 4


# ‚ú® 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Log ‡∏Ç‡∏≠‡∏á Error
def create_error_log_entry(user_input: str, error_message: str, failure_type: str) -> dict:
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Dictionary ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
    """
    print(f"INFO: Creating error log entry. Type: '{failure_type}', Details: {error_message}")

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
    status = 'requires_manual_reply' if failure_type in ['full_fallback_failed', 'core_logic_error', 'initialization_error'] else 'requires_review'

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞ return Dictionary ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤
    error_entry = {
        'role': 'user', # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏°‡∏≤‡∏à‡∏≤‡∏Å user
        'parts': [{'text': user_input}],
        'status': status,
        'failure_type': failure_type,
        'error_details': error_message,
        'timestamp': datetime.datetime.now(datetime.timezone.utc).isoformat()
    }
    return error_entry


# ‚ú® 2. ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô get_bot_response ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà
def get_bot_response(
    tenant_id: str,
    user_id: str,
    user_input: str,
    platform: str = "unknown",
    display_name: Optional[str] = None,
    last_message_time: Optional[str] = None
) -> str:
    """
    Generates a bot response using Gemini, with OpenAI fallback, and robust error logging.
    """
    end_user_model = get_gemini_end_user_model()
    openai_client = get_openai_client()
    history_ref = db.collection('chat_sessions').document(tenant_id).collection('users').document(user_id)
    
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó
    try:
        tenant_ref = db.collection('tenants').document(tenant_id)
        tenant_data = tenant_ref.get()
        if not tenant_data.exists:
            return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£"
        config = tenant_data.to_dict()

        history_doc = history_ref.get()
        user_profile_data = history_doc.to_dict() if history_doc.exists else {}
        history_data_from_db = user_profile_data.get('history', [])
        current_summary = user_profile_data.get('summary', "")
        
        # --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡πâ‡∏î Summarization ---
        messages_to_summarize = [msg for msg in history_data_from_db if not msg.get('summarized', False)]
        if len(messages_to_summarize) > SUMMARIZATION_THRESHOLD and end_user_model:
            print(f"üîÑ Tenant {tenant_id}: New messages exceed threshold. Attempting summarization...")
            try:
                new_conversation_text = ""
                for msg in messages_to_summarize:
                    role = msg['role']
                    text_parts = [part['text'] for part in msg['parts'] if 'text' in part]
                    new_conversation_text += f"{role}: {' '.join(text_parts)}\n"
                context_for_summarizer = f"PREVIOUS SUMMARY:\n{current_summary}\n\n---\n\nNEW MESSAGES TO ADD TO SUMMARY:\n{new_conversation_text}"
                summarization_chat = end_user_model.start_chat(history=[])
                summary_response = summarization_chat.send_message(
                    SUMMARIZATION_PROMPT.format(conversation_history=context_for_summarizer)
                )
                new_summary = summary_response.text
                print(f"‚úÖ Tenant {tenant_id}: Summarization successful.")
                current_summary = new_summary
                for msg in history_data_from_db:
                    if not msg.get('summarized'):
                        msg['summarized'] = True
                print(f"‚úÖ Tenant {tenant_id}: Marked {len(messages_to_summarize)} messages as summarized.")
            except Exception as sum_e:
                # ‡∏´‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á Log ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ
                error_entry = create_error_log_entry(user_input, str(sum_e), "summarization_failed")
                history_data_from_db.append(error_entry)
                print(f"‚ö†Ô∏è Tenant {tenant_id}: Summarization failed but process continues.")

        # --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á Prompt Template ---
        behavioral_instructions = []
        if config.get('is_detailed_response', False): behavioral_instructions.append("- ‡∏à‡∏á‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô")
        else: behavioral_instructions.append("- ‡∏à‡∏á‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô")
        if config.get('is_sweet_tone', False): behavioral_instructions.append("- ‡∏à‡∏á‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≠‡∏ô‡∏´‡∏ß‡∏≤‡∏ô ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°")
        else: behavioral_instructions.append("- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏≠‡∏î‡πÅ‡∏ó‡∏£‡∏Å‡∏°‡∏∏‡∏Å‡∏ï‡∏•‡∏Å‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡∏ô‡πâ‡∏≠‡∏¢‡πÜ ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡∏ó‡∏µ‡πà‡∏î‡∏π‡πÄ‡∏ó‡πà‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢‡πÑ‡∏î‡πâ")
        if config.get('show_empathy', False): behavioral_instructions.append("- ‡∏à‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏™‡πà‡πÉ‡∏à‡πÉ‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡∏ñ‡∏≤‡∏°‡πÑ‡∏ñ‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏´‡πà‡∏ß‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏¢")
        if config.get('high_sales_drive', False): behavioral_instructions.append("- ‡∏à‡∏á‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏™‡∏ô‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à")
        else: behavioral_instructions.append("- ‡∏à‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏î‡∏î‡∏±‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏ã‡∏∑‡πâ‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤")
        behavioral_prompt_section = "\n".join(behavioral_instructions)
        base_persona = config.get('botPersona', "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI")
        prompt_template = f"{base_persona}\n\n--- ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ô‡∏¥‡∏™‡∏±‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ---\n{behavioral_prompt_section}"
        knowledge_base = config.get('knowledgeBase', "")
        
        # --- ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° History ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Model ---
        chat_history_for_model = []
        if current_summary:
            chat_history_for_model.append(content_types.to_content({'role': 'user', 'parts': [{'text': f"Summary of previous conversation:\n{current_summary}"}]}))
            chat_history_for_model.append(content_types.to_content({'role': 'model', 'parts': [{'text': "OK, I understand the context."}]}))
        
        clean_history = [{'role': item['role'], 'parts': item['parts']} for item in history_data_from_db[-RECENT_MESSAGES_TO_KEEP:] if item.get('status') is None]
        chat_history_for_model.extend([content_types.to_content(item) for item in clean_history])

        keywords = re.split(r'\s+', user_input)
        relevant_chunks = [chunk.strip() for chunk in knowledge_base.split('###') if any(kw in chunk for kw in keywords if len(kw) > 2)]
        retrieved_info = "\n\n".join(relevant_chunks) if relevant_chunks else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á"
        final_prompt = f"{prompt_template}\n\n--- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ---\n{retrieved_info}\n\n--- ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ---\n{user_input}"

    except Exception as e:
        print(f"‚ùå INITIALIZATION ERROR for tenant {tenant_id}, user {user_id}: {e}")
        error_entry = create_error_log_entry(user_input, str(e), "initialization_error")
        try:
            history_ref.update({'history': firestore.ArrayUnion([error_entry])})
        except Exception as db_e:
            print(f"‚ùå CRITICAL DB ERROR during init: Could not log error. Reason: {db_e}")
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"

    # --- ‡∏™‡πà‡∏ß‡∏ô Logic ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà ---
    history_to_save = list(history_data_from_db)
    reply_msg = ""
    is_successful = False

    try:
        if not end_user_model: raise Exception("Gemini model not available")
        chat = end_user_model.start_chat(history=chat_history_for_model)
        response = chat.send_message(final_prompt)
        reply_msg = response.text
        is_successful = True
        print(f"‚úÖ Tenant {tenant_id}: Got response from Gemini.")

    except Exception as gemini_e:
        print(f"‚ö†Ô∏è Tenant {tenant_id}: Gemini failed ({gemini_e}). Attempting fallback to OpenAI...")
        try:
            if not openai_client: raise Exception("OpenAI client not available for fallback")
            openai_messages = []
            if current_summary: openai_messages.append({"role": "system", "content": f"Summary of previous conversation:\n{current_summary}"})
            openai_messages.extend([{"role": "assistant" if item['role'] == 'model' else item['role'], "content": ' '.join([p['text'] for p in item['parts'] if 'text' in p])} for item in clean_history])
            openai_messages.append({"role": "user", "content": final_prompt})
            completion = openai_client.chat.completions.create(model="gpt-3.5-turbo", messages=openai_messages)
            reply_msg = completion.choices[0].message.content
            is_successful = True
            print(f"‚úÖ Tenant {tenant_id}: Got response from OpenAI fallback.")
        except Exception as openai_e:
            print(f"‚ùå Tenant {tenant_id}: OpenAI fallback also failed: {openai_e}")
            error_entry = create_error_log_entry(user_input, str(openai_e), "full_fallback_failed")
            history_to_save.append(error_entry)
            reply_msg = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á"

    # --- ‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á DB ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ---
    try:
        if is_successful:
            user_msg_for_history = {
                'role': 'user',
                'parts': [{'text': user_input}],
                'timestamp': datetime.datetime.now(datetime.timezone.utc).isoformat()
            }
            model_reply_for_history = {
                'role': 'model',
                'parts': [{'text': reply_msg}],
                'timestamp': datetime.datetime.now(datetime.timezone.utc).isoformat()
            }
            history_to_save.append(user_msg_for_history)
            history_to_save.append(model_reply_for_history)
        
        user_profile_data['history'] = history_to_save
        user_profile_data['summary'] = current_summary
        user_profile_data['lastMessageTime'] = last_message_time if last_message_time else datetime.datetime.now(datetime.timezone.utc).isoformat()
        if display_name: user_profile_data['displayName'] = display_name
        if 'platform' not in user_profile_data: user_profile_data['platform'] = platform

        history_ref.set(user_profile_data)
        print(f"‚úÖ Tenant {tenant_id}: Final data saved to Firestore. Success: {is_successful}")

    except Exception as final_db_e:
        print(f"‚ùå CRITICAL FINAL SAVE ERROR for tenant {tenant_id}: {final_db_e}")

    return reply_msg